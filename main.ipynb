{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MICRO-452:] Project Report\n",
    "\n",
    "\n",
    "\n",
    "<p><b>Authors:</b> &nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;Antoine Rol, Ruben Jungius, Hugo Masson, Jadd<br>\n",
    "<b>Supervisors:</b> &nbsp;&emsp;&emsp;&emsp;Prof. Francesco Mondada<br>\n",
    "<b>Due date:</b>  &nbsp;&nbsp;&nbsp;&emsp;&emsp;&emsp;&emsp;December 7th, 2023</p>\n",
    "<b>Presentation date:</b> &nbsp;&nbsp;December 14th, 2023</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Thymhiker  </center></h1>\n",
    "<img src=\"\" style=\"width: 600px;\"> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1><br>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1.&nbsp;&nbsp;</span>Introduction</a></span></li></ul><ul class=\"toc-item\"><li><a href=\"#Project-summary-,-hardware-and-choices\" data-toc-modified-id=\"Project-summary-,-hardware-and-choices-2\"><span class=\"toc-item-num\">2.&nbsp;&nbsp;</span>Project summary, hardware and choices</a></li></ul><ul class=\"toc-item\"><li><span><a href=\"#Vision\" data-toc-modified-id=\"Vision-3\"><span class=\"toc-item-num\">3.&nbsp;&nbsp;</span>Vision</a></span></li></ul><ul class=\"toc-item\"><li><a href=\"#Global-navigation\" data-toc-modified-id=\"Global-navigation-4\"><span class=\"toc-item-num\">4.&nbsp;&nbsp;</span>Global navigation</a></li></ul><ul class=\"toc-item\"><li><a href=\"#Local-navigation\" data-toc-modified-id=\"Local-navigation-5\"><span class=\"toc-item-num\">5.&nbsp;&nbsp;</span>Local navigation</a></li></ul><ul class=\"toc-item\"><li><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-6\"><span class=\"toc-item-num\">6.&nbsp;&nbsp;</span>Filtering</a></li></ul><ul class=\"toc-item\"><li><a href=\"#Motion-control\" data-toc-modified-id=\"Motion-control-7\"><span class=\"toc-item-num\">7.&nbsp;&nbsp;</span>Motion control</a></li></ul><ul class=\"toc-item\"><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-8\"><span class=\"toc-item-num\">8.&nbsp;&nbsp;</span>Conclusion</a></span></li></ul><ul class=\"toc-item\"><li><a href=\"#Main\" data-toc-modified-id=\"Main-9\"><span class=\"toc-item-num\">9.&nbsp;&nbsp;</span>Main</a></ul> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "<a class=\"anchor\" id=\"Introduction\"></a>\n",
    "<p style='text-align: justify;'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The narrative behind this mobile robotic project involves a hiker. He has to reach a goal position, which is a refuge defined by a tag. On his way, there are black obstacles, which are volcanoes that the Thymio should avoid. Fortunately, he has a plan where the volcanoes are marked. He just has to decide on the best path to stay safe, then proceed along this route and not forget to dodge rocks that are not marked on the map.\n",
    "This project contains 5 majors parts. \n",
    "\n",
    "- The **vision** : The goal of this part is to obtain the obstacle map and the goal position in offline mode, and then acquire the Thymio's real-time position and orientation.\n",
    "\n",
    "- **Global Path** : Utilizing the obstacle map from the Vision part, this section computes the optimal path for the hiker to stay safe. A visibility graph algorithm will be applied, resulting in a list of path point coordinates.\n",
    "\n",
    "- **Local Naviguation** : This section prevents the hiker from colliding with rocks not on the obstacle map. A neural network will be used for this function\n",
    "\n",
    "- **Motion control** : Using the list of path point coordinates from the Global Navigation part, this part controls the speed of the left and right motors to accurately follow the path.\n",
    "\n",
    "- **Filtering** with Kalman filter : In this section, a Kalman filter will be implemented to achieve a more precise position estimation and orientation. The objective is to maintain reliable estimates of orientation and position even in the absence of the camera signal.\n",
    "\n",
    "Below, you will find a grafcet showing the implementation of each part and their interconnections.\n",
    "\n",
    "<img src=\"images_rapport\\grafcet.PNG\" style=\"width: 700px;\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Project summary, hardware and choices\n",
    "<a class=\"anchor\" id=\"Project-summary-,-hardware-and-choices\"></a>\n",
    "### Project summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Vision\n",
    "<a class=\"anchor\" id=\"Vision\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Global navigation\n",
    "<a class=\"anchor\" id=\"Global-navigation\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Local Navigation\n",
    "<a class=\"anchor\" id=\"Local-navigation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local navigation runs continuously, serving as the Thymio's last line of defense against collisions with unforeseen or vision-unseen obstacles. In this phase, the priority is to prevent any collisions, disregarding the predetermined path provided by global navigation.\n",
    "\n",
    "Obstacle avoidance is executed using a Neural Network. The inputs for the Neural Network are the proximity IR sensors arranged around the Thymio (prox in the code). The outputs consist of speed inputs for the right and left motors (motorL and motorR in the code). Between these outputs, there are weights organized in a 2x5 matrix format (NNW in the code). These weights are designed to assign more significance to obstacles directly in front of the Thymio than those on its sides. This adjustment helps the robot turn more when the obstacle is in front, as opposed to being at the extremities of the robot.\n",
    "\n",
    "To prevent the robot from being repulsed by distant walls, a threshold is implemented. Below this threshold, the robot does not consider the obstacle. Additionally, a Gain is applied to the motor speed values, allowing for the adjustment of the avoidance system's reactivity according to preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def LocalAvoidance(prox) : \n",
    "    \n",
    "    NNW = np.array([[2, 3, -4, -3, -2],[-2, -3, -4, 3, 2]])\n",
    "    threshold = 500\n",
    "    Gain = 0.01\n",
    "    obstacle_detected = False\n",
    "    prox_for = np.zeros(5)\n",
    "\n",
    "    for i in range(5):\n",
    "        prox_for[i] = prox[i]\n",
    "        if(prox[i] > threshold) :\n",
    "            obstacle_detected = True\n",
    "\n",
    "    if not(obstacle_detected) :\n",
    "        return 0, 0\n",
    "\n",
    "    elif obstacle_detected :\n",
    "        Y = np.dot(NNW, prox_for) * Gain\n",
    "        motor_L = Y[0] \n",
    "        motor_R = Y[1]\n",
    "        return motor_L, motor_R\n",
    "\n",
    "#Test part : \n",
    "prox_test = [2200,1500, 400, 0,0 ] # sensor values wich correspond to an right sided obstacle\n",
    "print(LocalAvoidance(prox_test))   # output : we avoid the obstacle by turning on the right "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow is a video of the robot avoiding an obstacle. For the demonstration, the speed motors on both side has been set to 200. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Filtering\n",
    "<a class=\"anchor\" id=\"Filtering\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Motion Control\n",
    "<a class=\"anchor\" id=\"Motion-control\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The motion control's primary objective is to determine the motor speeds for the left and right sides based on the robot's position (x, y), orientation (theta), and the array of path coordinates. As a reminder, the global navigation part provides us with a list of points that the Thymio needs to reach.\n",
    "\n",
    "For accurate line following, we have drawn inspiration from steering behavior path following. In this context, steering behaviors encompass a set of algorithms or techniques used to control the movement of autonomous agents or entities in a virtual environment, simulating natural and intelligent motion.\n",
    "\n",
    "Within these techniques, we specifically focus on the \"seek\" concept, which involves moving towards a target point defined on the path. In our code, this target point is referred to as the \"carrot.\" In summary, the path-following algorithm comprises two parts:\n",
    "\n",
    "- Compute the carrot position.\n",
    "- Move toward the carrot using a P controller.\n",
    "\n",
    "\n",
    "**Compute the carrot position :**\n",
    "To compute the carrot position, we inspired ourselves from this video : https://www.youtube.com/watch?v=rlZYT-uvmGQ&t=16s \n",
    "\n",
    "(1) Initially, we calculate the position projection, denoted as 'projection,' using the Thymio's orientation and a parameter called d_projection.\n",
    "\n",
    "(2) Subsequently, we create two vectors. Vector A represents the vector from the beginning of the segment to the path point, and vector B is the normalized vector from the beginning of the segment to the end.\n",
    "\n",
    "(3) Next, we perform a scalar projection of A onto B, resulting in the value sp.\n",
    "\n",
    "(4) Finally, we compute the carrot position by projecting sp in the direction of B, starting from the robot's position.\n",
    "\n",
    "The first parameter to adjust is d_projection, which determines the horizon of the Thymio. If it's too short, the Thymio will react at the last moment during turns. If it's too long, the Thymio will be less responsive.\n",
    "\n",
    "The second parameter is Kpteta, which is experimentally determined. If it's too large, the Kalman filter may oscillate; if it's too low, the Thymio will turn too slowly.\n",
    "\n",
    "\n",
    "**Go to the carrot :**\n",
    "This section is responsible for determining the motor speeds based on inputs such as the robot's position, the angle (theta), the carrot position, and the projection.\n",
    "\n",
    "(5) Initially, we set the motor speeds to the same value, representing the speed of the robot when the carrot is directly in front of the Thymio.\n",
    "\n",
    "(6) Subsequently, we calculate the distance between the 'projection' and the carrot.\n",
    "        If the distance is less than the margin, we keep the motor speeds unchanged.\n",
    "        Otherwise, we compute the angle Phi, which is the angle between the Thymio's orientation and the ideal orientation to reach the carrot.\n",
    "                Then, we adjust the motor speeds using a P controller: motorR = motorR - phi * KPangle.\n",
    "\n",
    "Here is a schema to make it more simple and the code :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_rapport\\Schema_pathfollow.jpg\" style=\"width: 700px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPteta = 70\n",
    "segment_idx = 0\n",
    "\n",
    "# function to know the distance beetwin 2 points\n",
    "def distance(point1, point2):\n",
    "    \n",
    "    return math.sqrt((point2[0] - point1[0])**2 + (point2[1] - point1[1])**2)\n",
    "\n",
    "# function to compute a vector form 2 points\n",
    "def vector_compute(point1, point2):\n",
    "\n",
    "    vecteur = (point2[0] - point1[0], point2[1] - point1[1])\n",
    "    return vecteur\n",
    "\n",
    "# fucntion to bond an angle beetwin -pi and pi  \n",
    "def adjust_angle(_angle):\n",
    "\n",
    "    while _angle > math.pi:\n",
    "        _angle -= 2*math.pi\n",
    "    while _angle < -math.pi:\n",
    "        _angle += 2*math.pi\n",
    "    return _angle\n",
    "\n",
    "\n",
    "\n",
    "def go_to_carrot(_position, _carrot, _teta, _margin) : \n",
    "\n",
    "    motorL = 0\n",
    "    motorR = 0\n",
    "    motorL = 70\n",
    "    motorR = 70\n",
    "\n",
    "    d = distance(_position, _carrot)    # function to know the distance beetwin 2 points\n",
    "    vector_carrot = vector_compute(_position, _carrot)\n",
    "    if d > _margin :\n",
    "        phi =  math.atan2(vector_carrot[1],vector_carrot[0]) - _teta\n",
    "        phi = adjust_angle(phi)     \n",
    "        motorL = motorL + phi * KPteta\n",
    "        motorR = motorR - phi * KPteta\n",
    "\n",
    "    return motorL, motorR\n",
    "\n",
    "\n",
    "def follow_path(position, teta, path, path_has_been_done) :\n",
    "\n",
    "    # Initialization of the variables\n",
    "    projection = np.array([0,0])\n",
    "    carrot = np.array([0,0])\n",
    "    motorL = 0\n",
    "    motorR = 0\n",
    "    global segment_idx  #index of the target segment. (the segment wich the robot is following)\n",
    "    \n",
    "    # Set parameters\n",
    "    margin = 5 # margin around the line  \n",
    "    d_projection = 30   # distance from the robot to the projection \n",
    "    has_finished = 0    # flag to know if the robot has reached the last point\n",
    "    limit_distance = 40     # distance in pixels to know if the robot has reached the end of an segment\n",
    "    \n",
    "\n",
    "    # Ckech if the path planning just came to be done \n",
    "    if path_has_been_done == 1 :\n",
    "        segment_idx = 0\n",
    "        path_has_been_done = 0\n",
    "\n",
    "    # Check if the position has reached the end segment point\n",
    "    if distance(position, path[segment_idx +1]) < limit_distance : \n",
    "        segment_idx += 1\n",
    "        print('let s change segemnt')\n",
    "        if segment_idx == len(path)-1 :\n",
    "            has_finished = 1\n",
    "            print('End')\n",
    "\n",
    "    # Check if the Thymio has reached the end \n",
    "    if has_finished == 1:\n",
    "        motorL = 0\n",
    "        motorR = 0\n",
    "        return motorL, motorR, has_finished\n",
    "    else : \n",
    "        # step(1)\n",
    "        projection = position + np.array([d_projection*math.cos(teta), d_projection*math.sin(teta)])\n",
    "        # step(2)\n",
    "        A = vector_compute(path[segment_idx], projection)\n",
    "        B = vector_compute(path[segment_idx], path[segment_idx+1])\n",
    "        Bnormal = B / np.linalg.norm(B)\n",
    "        #step(3)\n",
    "        sp = abs(np.dot(A,Bnormal))\n",
    "        maxsp = distance(path[segment_idx],path[segment_idx+1])\n",
    "        if sp >maxsp : \n",
    "            sp = maxsp\n",
    "        #step(4)\n",
    "        carrot = path[segment_idx] + Bnormal * sp\n",
    "        \n",
    "        \n",
    "        motorL, motorR = go_to_carrot(position, carrot, teta, Bnormal, margin)\n",
    "        return motorL, motorR, has_finished\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIII . Conclusion\n",
    "<a class=\"anchor\" id=\"Conclusion\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
